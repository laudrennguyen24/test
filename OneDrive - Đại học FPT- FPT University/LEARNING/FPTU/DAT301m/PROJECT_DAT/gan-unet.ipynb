{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11051109,"sourceType":"datasetVersion","datasetId":6884732}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sewar","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport h5py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport cv2\nfrom tensorflow.keras.layers import Input,Dense,Reshape,Conv2D,Dropout,multiply,Dot,Concatenate,subtract,ZeroPadding2D\nfrom tensorflow.keras.layers import BatchNormalization,LeakyReLU,Flatten\nfrom tensorflow.keras.layers import Conv2DTranspose as Deconv2d\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom PIL import Image\nfrom scipy.linalg import sqrtm\nfrom skimage.metrics import structural_similarity as ssim\nfrom sewar.full_ref import vifp, msssim, psnr\n    \nfrom keras import backend as K\nimport smtplib\n\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\nimport keras\nfrom keras import layers\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm import tqdm\nimport re\nfrom tensorflow.keras.preprocessing.image import img_to_array\nimport random\nfrom tensorflow.keras.models import load_model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T01:40:52.046436Z","iopub.execute_input":"2025-03-17T01:40:52.046759Z","iopub.status.idle":"2025-03-17T01:41:10.608690Z","shell.execute_reply.started":"2025-03-17T01:40:52.046734Z","shell.execute_reply":"2025-03-17T01:41:10.607837Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def sorted_alphanumeric(data):\n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n    return sorted(data, key=alphanum_key)\n\nSIZE = 128\n\ncolor_img = []\npath = r'/kaggle/input/augmented-dataset-cp/color'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)  # Giới hạn số ảnh đọc vào\n\nfor i in tqdm(files):\n    img = cv2.imread(os.path.join(path, i), 1)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (SIZE, SIZE))6\n    img = img.astype('float32') / 255.0\n    color_img.append(img_to_array(img))\n\ngray_img = []\npath = r'/kaggle/input/augmented-dataset-cp/gray'\nfiles = os.listdir(path)\nfiles = sorted_alphanumeric(files)  # Giới hạn số ảnh đọc vào\n\nfor i in tqdm(files):\n    img = cv2.imread(os.path.join(path, i), 1)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (SIZE, SIZE))\n    img = img.astype('float32') / 255.0\n    gray_img.append(img_to_array(img))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T01:41:10.609654Z","iopub.execute_input":"2025-03-17T01:41:10.610175Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 38604/38604 [07:12<00:00, 89.33it/s] \n 63%|██████▎   | 24192/38604 [04:19<02:36, 92.28it/s] ","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"def image_generator(images):\n    for img in images:\n        yield img\n\ncolor_dataset = tf.data.Dataset.from_generator(lambda: image_generator(color_img), output_signature=tf.TensorSpec(shape=(SIZE, SIZE, 3), dtype=tf.float32))\ngray_dataset = tf.data.Dataset.from_generator(lambda: image_generator(gray_img)6, output_signature=tf.TensorSpec(shape=(SIZE, SIZE, 3), dtype=tf.float32))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def downsample(filters, size, apply_batchnorm=True):\n    result = tf.keras.Sequential()\n    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n                                      kernel_initializer='he_normal', use_bias=not apply_batchnorm))\n    if apply_batchnorm:\n        result.add(tf.keras.layers.BatchNormalization())\n\n    result.add(tf.keras.layers.LeakyReLU())\n    return result\n\n\ndef upsample(filters, size, apply_dropout=False):\n\n  result = tf.keras.Sequential()\n  result.add(tf.keras.layers.Conv2DTranspose(filters, size, strides=2,padding='same',kernel_initializer='he_normal',use_bias=False))\n  result.add(tf.keras.layers.BatchNormalization())\n\n  if apply_dropout:\n      result.add(tf.keras.layers.Dropout(0.5))\n\n  result.add(tf.keras.layers.ReLU())\n  return result","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\ndef Generator():\n    inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n\n    down_stack = [\n        downsample(64, 4, apply_batchnorm=False),  \n        downsample(128, 4), \n        downsample(256, 4), \n        downsample(384, 4),  \n        downsample(384, 4), \n        downsample(512, 4),  \n    ]\n\n    up_stack = [\n        upsample(512, 4, apply_dropout=True), \n        upsample(384, 4, apply_dropout=True), \n        upsample(256, 4), \n        upsample(128, 4),  \n        upsample(64, 4),  \n        upsample(32, 4), \n    ]\n\n    last = tf.keras.layers.SeparableConv2D(3, kernel_size=3, strides=1, padding='same', activation='tanh')\n\n    x = inputs\n    skips = []\n\n    for down in down_stack:\n        x = down(x)\n        skips.append(x)\n\n    skips = reversed(skips[:-1])  \n\n    for up, skip in zip(up_stack[:-1], skips):\n        x = up(x)\n        x = tf.keras.layers.Concatenate()([x, skip])\n\n    x = up_stack[-1](x)\n\n    # Tầng đầu ra\n    x = last(x)\n\n    return tf.keras.Model(inputs=inputs, outputs=x)\n\n# Kiểm tra mô hình\ngenerator = Generator()\ngenerator.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\ndef downsample(filters, size, apply_batchnorm=True):\n    initializer = tf.random_normal_initializer(0., 0.02)\n    \n    result = tf.keras.Sequential()\n    result.add(tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\n                                      kernel_initializer=initializer, use_bias=False))\n    \n    if apply_batchnorm:\n        result.add(tf.keras.layers.BatchNormalization())\n\n    result.add(tf.keras.layers.LeakyReLU())\n\n    return result\n\ndef Discriminator():\n    initializer = tf.random_normal_initializer(0., 0.02)\n\n    inp = tf.keras.layers.Input(shape=[128, 128, 3], name='input_image')\n    tar = tf.keras.layers.Input(shape=[128, 128, 3], name='target_image')\n\n    x = tf.keras.layers.Concatenate()([inp, tar])  # (bs, 128, 128, 6)\n\n    down1 = downsample(64, 4, apply_batchnorm=False)(x)   # (bs, 64, 64, 64)\n    down2 = downsample(128, 4)(down1)  # (bs, 32, 32, 128)\n    down3 = downsample(256, 4)(down2)  # (bs, 16, 16, 256)\n    down4 = downsample(512, 4)(down3)  # (bs, 8, 8, 512)\n    down5 = downsample(512, 4)(down4)  # (bs, 4, 4, 512)\n    down6 = downsample(512, 4)(down5)  # (bs, 2, 2, 512) ✅\n\n    conv = tf.keras.layers.Conv2D(512, 4, strides=1, padding='same',\n                                  kernel_initializer=initializer, use_bias=False)(down6)  # (bs, 2, 2, 512)\n    batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\n    leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\n\n    last = tf.keras.layers.Conv2D(1, 4, strides=1, padding='same',\n                                  kernel_initializer=initializer)(leaky_relu)  # (bs, 2, 2, 1) ✅\n\n    return tf.keras.Model(inputs=[inp, tar], outputs=last)\n\n# Test model\ndiscriminator = Discriminator()\ndiscriminator.summary()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"disc = Discriminator()\nsample_input = tf.random.normal([1, 128, 128, 3])\nsample_target = tf.random.normal([1, 128, 128, 3])\noutput = disc([sample_input, sample_target])\nprint(f\"Discriminator output shape: {output.shape}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"genLoss=[]\ndiscLoss=[]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)\ngenerator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)  # Giữ nguyên\ndiscriminator_optimizer = tf.keras.optimizers.Adam(7e-5, beta_1=0.5, weight_decay=1e-4)\n\nLAMBDA = 150\n\ndef generator_loss(disc_generated_output, gen_output, target):\n  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\n\n  # mean absolute error\n  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n\n  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\n  genLoss.append(total_gen_loss)\n\n  return total_gen_loss, gan_loss, l1_loss\n\ndef discriminator_loss(disc_real_output, disc_generated_output):\n  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\n\n  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\n\n  total_disc_loss = real_loss + generated_loss\n  discLoss.append(total_disc_loss)\n\n  return total_disc_loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_step(input_image, target, epoch):\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        gen_output = generator(input_image, training=True)\n        \n        gen_output = tf.image.resize(gen_output, (128, 128))\n        \n        disc_real_output = discriminator([input_image, target], training=True)\n        disc_generated_output = discriminator([input_image, gen_output], training=True)\n        \n        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n\n    generator_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n    discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n    \n    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n\n    return gen_total_loss, gen_gan_loss, gen_l1_loss, disc_loss  # ✅ Trả về loss\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\ndef fit(train_ds, epochs):\n    history = {'gen_loss': [], 'gen_gan_loss': [], 'gen_l1_loss': [], 'disc_loss': []}\n\n    for epoch in range(epochs):\n        start = time.time()\n        total_gen_loss, total_gan_loss, total_l1_loss, total_disc_loss = 0, 0, 0, 0\n        num_batches = 0\n\n        print(\"Epoch:\", epoch+1)\n        for n, (input_image, target) in train_ds.enumerate():\n            gen_loss, gan_loss, l1_loss, disc_loss = train_step(input_image, target, epoch)\n\n            total_gen_loss += gen_loss.numpy()\n            total_gan_loss += gan_loss.numpy()\n            total_l1_loss += l1_loss.numpy()\n            total_disc_loss += disc_loss.numpy()\n            num_batches += 1\n\n        avg_gen_loss = total_gen_loss / num_batches\n        avg_gan_loss = total_gan_loss / num_batches\n        avg_l1_loss = total_l1_loss / num_batches\n        avg_disc_loss = total_disc_loss / num_batches\n\n        history['gen_loss'].append(avg_gen_loss)\n        history['gen_gan_loss'].append(avg_gan_loss)\n        history['gen_l1_loss'].append(avg_l1_loss)\n        history['disc_loss'].append(avg_disc_loss)\n\n        print(f\"Epoch {epoch+1}: Gen Loss: {avg_gen_loss:.4f}, GAN Loss: {avg_gan_loss:.4f}, L1 Loss: {avg_l1_loss:.4f}, Disc Loss: {avg_disc_loss:.4f}\")\n        print(f\"Time taken for epoch {epoch+1} is {time.time()-start:.2f} sec\\n\")\n\n        # Lưu trọng số mỗi 5 epoch\n        if (epoch + 1) % 5 == 0:\n            generator.save(f'generator_epoch_{epoch+1}.weights.h5')\n            discriminator.save(f'discriminator_epoch_{epoch+1}.weights.h5')\n            print(f\"Đã lưu trọng số tại Epoch {epoch+1}\")\n\n    return history\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BATCH_SIZE = 16\ntrain_dataset = tf.data.Dataset.zip((\n    gray_dataset.batch(BATCH_SIZE),\n    color_dataset.batch(BATCH_SIZE)\n))#.shuffle(1000)  # Shuffle để tránh overfitting","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for input_image, target in train_dataset.take(1):\n    print(\"Input shape:\", input_image.shape)\n    print(\"Target shape:\", target.shape)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hist = fit(train_dataset, epochs=20)\nhist  \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nsns.set(style='whitegrid')\nplt.figure(figsize=(10,4))\nplt.plot(genLoss, label=\"Generator Loss\")\nplt.plot(discLoss, label=\"Discriminator Loss\")\nplt.title(\"GAN LOSS VALUES\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}